{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":68479,"databundleVersionId":7609535,"sourceType":"competition"},{"sourceId":7009925,"sourceType":"datasetVersion","datasetId":4030196}],"dockerImageVersionId":30646,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%%capture\n!pip install scikit-learn xgboost lightgbm catboost\n\nimport pandas as pd\nimport numpy as np\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport warnings \nwarnings.filterwarnings('ignore')\n\nimport tensorflow as tf\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, BatchNormalization, Dropout\nfrom keras.layers import LeakyReLU,PReLU,ELU\nfrom tensorflow.keras.utils import to_categorical\nfrom keras.callbacks import EarlyStopping\n\nfrom sklearn.metrics import roc_auc_score, accuracy_score\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier\nfrom catboost import CatBoostClassifier","metadata":{"_kg_hide-input":false,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2024-02-17T09:52:08.019253Z","iopub.execute_input":"2024-02-17T09:52:08.019646Z","iopub.status.idle":"2024-02-17T09:52:42.736745Z","shell.execute_reply.started":"2024-02-17T09:52:08.019616Z","shell.execute_reply":"2024-02-17T09:52:42.735694Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"2024-02-17 09:52:26.472093: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-02-17 09:52:26.472258: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-02-17 09:52:26.648073: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"#Loading the dataset again to revert previously made changed on BMI etc.\ndf_train = pd.read_csv('/kaggle/input/playground-series-s4e2/train.csv')\noriginal = pd.read_csv('/kaggle/input/obesity-or-cvd-risk-classifyregressorcluster/ObesityDataSet.csv')\ndf_test = pd.read_csv('/kaggle/input/playground-series-s4e2/test.csv')","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-02-17T09:52:47.818201Z","iopub.execute_input":"2024-02-17T09:52:47.819358Z","iopub.status.idle":"2024-02-17T09:52:48.029166Z","shell.execute_reply.started":"2024-02-17T09:52:47.819300Z","shell.execute_reply":"2024-02-17T09:52:48.028107Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def get_variable_types(dataframe):\n    continuous_vars = []\n    categorical_vars = []\n\n    for column in dataframe.columns:\n        if dataframe[column].dtype == 'object':\n            categorical_vars.append(column)\n        else:\n            continuous_vars.append(column)\n\n    return continuous_vars, categorical_vars\n\ncontinuous_vars, categorical_vars = get_variable_types(df_train)\ncategorical_vars.remove('NObeyesdad')","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2024-02-17T09:59:59.895788Z","iopub.execute_input":"2024-02-17T09:59:59.896246Z","iopub.status.idle":"2024-02-17T09:59:59.904248Z","shell.execute_reply.started":"2024-02-17T09:59:59.896207Z","shell.execute_reply":"2024-02-17T09:59:59.902928Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"train = pd.concat([df_train, original]).drop(['id'], axis=1).drop_duplicates()\ntest = df_test.drop(['id'], axis=1)","metadata":{"execution":{"iopub.status.busy":"2024-02-17T10:00:03.193163Z","iopub.execute_input":"2024-02-17T10:00:03.193641Z","iopub.status.idle":"2024-02-17T10:00:03.244844Z","shell.execute_reply.started":"2024-02-17T10:00:03.193607Z","shell.execute_reply":"2024-02-17T10:00:03.243806Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"train = pd.get_dummies(train, columns=categorical_vars, drop_first=True)\ntest = pd.get_dummies(test, columns=categorical_vars, drop_first=True)","metadata":{"execution":{"iopub.status.busy":"2024-02-17T10:00:05.476334Z","iopub.execute_input":"2024-02-17T10:00:05.476734Z","iopub.status.idle":"2024-02-17T10:00:05.539390Z","shell.execute_reply.started":"2024-02-17T10:00:05.476704Z","shell.execute_reply":"2024-02-17T10:00:05.538501Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"X = train.drop(['NObeyesdad'], axis=1)\ny = train['NObeyesdad']","metadata":{"execution":{"iopub.status.busy":"2024-02-17T10:09:19.352742Z","iopub.execute_input":"2024-02-17T10:09:19.353158Z","iopub.status.idle":"2024-02-17T10:09:19.361634Z","shell.execute_reply.started":"2024-02-17T10:09:19.353130Z","shell.execute_reply":"2024-02-17T10:09:19.360248Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# Splitting the dataset into the Training set and Test set\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)","metadata":{"execution":{"iopub.status.busy":"2024-02-17T10:09:22.182760Z","iopub.execute_input":"2024-02-17T10:09:22.183432Z","iopub.status.idle":"2024-02-17T10:09:22.196949Z","shell.execute_reply.started":"2024-02-17T10:09:22.183400Z","shell.execute_reply":"2024-02-17T10:09:22.196026Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# Feature Scaling\n# from sklearn.preprocessing import StandardScaler\n# sc = StandardScaler()\n# X_train = sc.fit_transform(X_train)\n# X_test = sc.transform(X_test)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-02-09T01:19:33.475707Z","iopub.execute_input":"2024-02-09T01:19:33.476750Z","iopub.status.idle":"2024-02-09T01:19:33.481056Z","shell.execute_reply.started":"2024-02-09T01:19:33.476713Z","shell.execute_reply":"2024-02-09T01:19:33.479854Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"\n# Define the objective function for Optuna optimization\nimport optuna\nfrom optuna.samplers import TPESampler\n\ndef objective(trial, X_train, y_train, X_test, y_test):\n     # Define parameters to be optimized for the LGBMClassifier\n     param = {\n         \"objective\": \"multiclass\",\n         \"metric\": \"multi_logloss\",\n         \"verbosity\": -1,\n         \"boosting_type\": \"gbdt\",\n         \"random_state\": 42,\n         \"num_class\": 7,\n         \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.05),\n         \"n_estimators\": trial.suggest_int(\"n_estimators\", 400, 600),\n         \"lambda_l1\": trial.suggest_float(\"lambda_l1\", 0.005, 0.015),\n         \"lambda_l2\": trial.suggest_float(\"lambda_l2\", 0.02, 0.06),\n         \"max_depth\": trial.suggest_int(\"max_depth\", 6, 14),\n         \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.3, 0.9),\n         \"subsample\": trial.suggest_float(\"subsample\", 0.8, 1.0),\n         \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 10, 50),\n     }\n\n # Create an instance of LGBMClassifier with the suggested parameters\n     lgbm_classifier = LGBMClassifier(**param)\n    \n# Fit the classifier on the training data\n     lgbm_classifier.fit(X_train, y_train)\n\n# Evaluate the classifier on the test data\n     score = lgbm_classifier.score(X_test, y_test)\n\n     return score\n\n# Split the data into training and test sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)  # Adjust the test_size as needed\n\n#Set up the sampler for Optuna optimization\nsampler = optuna.samplers.TPESampler(seed=42)  # Using Tree-structured Parzen Estimator sampler for optimization\n\n# Create a study object for Optuna optimization\nstudy = optuna.create_study(direction=\"maximize\", sampler=sampler)\n\n# Run the optimization process\nstudy.optimize(lambda trial: objective(trial, X_train, y_train, X_test, y_test), n_trials=3)\n\n# Get the best parameters after optimization\nbest_params = study.best_params\n\nprint('='*50)\nprint(best_params)\n","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2024-02-17T10:11:09.023845Z","iopub.execute_input":"2024-02-17T10:11:09.024368Z","iopub.status.idle":"2024-02-17T10:12:00.648460Z","shell.execute_reply.started":"2024-02-17T10:11:09.024330Z","shell.execute_reply":"2024-02-17T10:12:00.647135Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stderr","text":"[I 2024-02-17 10:11:10,472] A new study created in memory with name: no-name-589811d7-0dc2-4cb1-9b1a-80fe80146437\n[I 2024-02-17 10:11:32,677] Trial 0 finished with value: 0.9124534909170496 and parameters: {'learning_rate': 0.0249816047538945, 'n_estimators': 591, 'lambda_l1': 0.012319939418114049, 'lambda_l2': 0.04394633936788146, 'max_depth': 7, 'colsample_bytree': 0.3935967122017216, 'subsample': 0.8116167224336399, 'min_child_samples': 45}. Best is trial 0 with value: 0.9124534909170496.\n[I 2024-02-17 10:11:47,240] Trial 1 finished with value: 0.915517618734953 and parameters: {'learning_rate': 0.034044600469728355, 'n_estimators': 542, 'lambda_l1': 0.005205844942958024, 'lambda_l2': 0.05879639408647977, 'max_depth': 13, 'colsample_bytree': 0.4274034664069657, 'subsample': 0.8363649934414201, 'min_child_samples': 17}. Best is trial 1 with value: 0.915517618734953.\n[I 2024-02-17 10:12:00,642] Trial 2 finished with value: 0.9152987524622456 and parameters: {'learning_rate': 0.02216968971838151, 'n_estimators': 505, 'lambda_l1': 0.009319450186421156, 'lambda_l2': 0.03164916560792168, 'max_depth': 11, 'colsample_bytree': 0.3836963163912251, 'subsample': 0.8584289297070437, 'min_child_samples': 25}. Best is trial 1 with value: 0.915517618734953.\n","output_type":"stream"},{"name":"stdout","text":"==================================================\n{'learning_rate': 0.034044600469728355, 'n_estimators': 542, 'lambda_l1': 0.005205844942958024, 'lambda_l2': 0.05879639408647977, 'max_depth': 13, 'colsample_bytree': 0.4274034664069657, 'subsample': 0.8363649934414201, 'min_child_samples': 17}\n","output_type":"stream"}]},{"cell_type":"code","source":"# Best parameters obtained from Optuna optimization from notebook in comments\n# https://www.kaggle.com/code/moazeldsokyx/pgs4e2-highest-score-lgbm-hyperparameter-tuning/notebook\n\nbest_params = {\n    \"objective\": \"multiclass\",          # Objective function for the model\n    \"metric\": \"multi_logloss\",          # Evaluation metric\n    \"verbosity\": -1,                    # Verbosity level (-1 for silent)\n    \"boosting_type\": \"gbdt\",            # Gradient boosting type\n    \"random_state\": 42,       # Random state for reproducibility\n    \"num_class\": 7,                     # Number of classes in the dataset\n    'learning_rate': 0.030962211546832760,  # Learning rate for gradient boosting\n    'n_estimators': 500,                # Number of boosting iterations\n    'lambda_l1': 0.009667446568254372,  # L1 regularization term\n    'lambda_l2': 0.04018641437301800,   # L2 regularization term\n    'max_depth': 10,                    # Maximum depth of the trees\n    'colsample_bytree': 0.40977129346872643,  # Fraction of features to consider for each tree\n    'subsample': 0.9535797422450176,    # Fraction of samples to consider for each boosting iteration\n    'min_child_samples': 26             # Minimum number of data needed in a leaf\n}","metadata":{"execution":{"iopub.status.busy":"2024-02-09T01:19:43.555823Z","iopub.execute_input":"2024-02-09T01:19:43.556161Z","iopub.status.idle":"2024-02-09T01:19:43.561748Z","shell.execute_reply.started":"2024-02-09T01:19:43.556136Z","shell.execute_reply":"2024-02-09T01:19:43.560961Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"lgbm_classifier = LGBMClassifier(**best_params)\nlgbm_classifier.fit(X_train, y_train)\ny_pred = lgbm_classifier.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2024-02-17T10:15:51.353339Z","iopub.execute_input":"2024-02-17T10:15:51.353789Z","iopub.status.idle":"2024-02-17T10:16:07.399993Z","shell.execute_reply.started":"2024-02-17T10:15:51.353756Z","shell.execute_reply":"2024-02-17T10:16:07.398803Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"[LightGBM] [Warning] lambda_l2 is set=0.05879639408647977, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.05879639408647977\n[LightGBM] [Warning] lambda_l1 is set=0.005205844942958024, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.005205844942958024\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] lambda_l2 is set=0.05879639408647977, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.05879639408647977\n[LightGBM] [Warning] lambda_l1 is set=0.005205844942958024, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.005205844942958024\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003298 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 2059\n[LightGBM] [Info] Number of data points in the train set: 18276, number of used features: 23\n[LightGBM] [Info] Start training from score -2.109885\n[LightGBM] [Info] Start training from score -1.917163\n[LightGBM] [Info] Start training from score -1.958187\n[LightGBM] [Info] Start training from score -1.858972\n[LightGBM] [Info] Start training from score -1.655114\n[LightGBM] [Info] Start training from score -2.127182\n[LightGBM] [Info] Start training from score -2.083169\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] lambda_l2 is set=0.05879639408647977, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.05879639408647977\n[LightGBM] [Warning] lambda_l1 is set=0.005205844942958024, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.005205844942958024\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","output_type":"stream"}]},{"cell_type":"code","source":"accuracy_score(y_test, y_pred) ","metadata":{"execution":{"iopub.status.busy":"2024-02-17T10:16:30.154800Z","iopub.execute_input":"2024-02-17T10:16:30.155261Z","iopub.status.idle":"2024-02-17T10:16:30.174247Z","shell.execute_reply.started":"2024-02-17T10:16:30.155227Z","shell.execute_reply":"2024-02-17T10:16:30.172878Z"},"trusted":true},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"0.9139855548260013"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, classification_report\nprint(classification_report(y_test, y_pred))","metadata":{"execution":{"iopub.status.busy":"2024-02-09T01:20:12.195751Z","iopub.execute_input":"2024-02-09T01:20:12.196059Z","iopub.status.idle":"2024-02-09T01:20:12.303925Z","shell.execute_reply.started":"2024-02-09T01:20:12.196037Z","shell.execute_reply":"2024-02-09T01:20:12.303069Z"},"trusted":true},"execution_count":62,"outputs":[{"name":"stdout","text":"                     precision    recall  f1-score   support\n\nInsufficient_Weight       0.93      0.95      0.94       574\n      Normal_Weight       0.90      0.90      0.90       677\n     Obesity_Type_I       0.92      0.88      0.90       682\n    Obesity_Type_II       0.96      0.97      0.97       697\n   Obesity_Type_III       1.00      1.00      1.00       878\n Overweight_Level_I       0.81      0.83      0.82       525\nOverweight_Level_II       0.83      0.84      0.84       536\n\n           accuracy                           0.92      4569\n          macro avg       0.91      0.91      0.91      4569\n       weighted avg       0.92      0.92      0.92      4569\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"<div style=\"border-radius:10px; padding: 12px; background-color: #ffffff; font-size:140%; text-align:left\">\n⍟ Weight, Height, Age and FAF appear to be the most important features.<br>\n⍟ CH20, Time using technology devices (TUE), and NCP are the other key important features.\n\n\n\n    \n    \n","metadata":{}},{"cell_type":"code","source":"# Evaluate the best model on the test set\npredictions = lgbm_classifier.predict(test)","metadata":{"execution":{"iopub.status.busy":"2024-02-09T01:20:23.805849Z","iopub.execute_input":"2024-02-09T01:20:23.806198Z","iopub.status.idle":"2024-02-09T01:20:27.942946Z","shell.execute_reply.started":"2024-02-09T01:20:23.806171Z","shell.execute_reply":"2024-02-09T01:20:27.941612Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"code","source":"submission = pd.read_csv(\"/kaggle/input/playground-series-s4e2/sample_submission.csv\")\nsubmission[\"NObeyesdad\"] = predictions\nsubmission.to_csv(\"submission3.csv\", index=False)\nsubmission.head()","metadata":{"execution":{"iopub.status.busy":"2024-02-09T01:20:31.935694Z","iopub.execute_input":"2024-02-09T01:20:31.935998Z","iopub.status.idle":"2024-02-09T01:20:31.971661Z","shell.execute_reply.started":"2024-02-09T01:20:31.935975Z","shell.execute_reply":"2024-02-09T01:20:31.970386Z"},"trusted":true},"execution_count":66,"outputs":[{"execution_count":66,"output_type":"execute_result","data":{"text/plain":"      id          NObeyesdad\n0  20758     Obesity_Type_II\n1  20759  Overweight_Level_I\n2  20760    Obesity_Type_III\n3  20761      Obesity_Type_I\n4  20762    Obesity_Type_III","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>NObeyesdad</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>20758</td>\n      <td>Obesity_Type_II</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>20759</td>\n      <td>Overweight_Level_I</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>20760</td>\n      <td>Obesity_Type_III</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>20761</td>\n      <td>Obesity_Type_I</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>20762</td>\n      <td>Obesity_Type_III</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"<a id=\"toc\"></a>\n\n<a href=\"#toc\" style=\"background-color: #E1B12D; color: #ffffff; padding: 7px 10px; text-decoration: none; border-radius: 50px;\">Back to top</a><a id=\"toc\"></a>\n\n---","metadata":{}}]}